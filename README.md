# snowflake-dbt-s3-project
End-to-end Snowflake + dbt pipeline using AWS S3

# Snowflake + dbt Incremental Pipeline using AWS S3

## ğŸ“Œ Project Overview
This project demonstrates an end-to-end data pipeline built using **Snowflake**, **dbt**, and **AWS S3**.
It ingests semi-structured JSON data stored inside CSV files from S3, processes it in Snowflake,
and transforms it into analytics-ready tables using dbt.

---

## ğŸ—ï¸ Architecture
AWS S3 (CSV with JSON)
â†“
Snowflake External Stage
â†“
RAW Table (VARIANT)
â†“
dbt Ephemeral Model (JSON Flattening)
â†“
dbt Incremental Model (MERGE)

---

## ğŸ› ï¸ Tech Stack
- Snowflake
- dbt
- AWS S3
- SQL
- GitHub

---

## âš™ï¸ Key Features
- Snowflake warehouse with auto-suspend & auto-resume
- External stage using S3 storage integration
- JSON parsing using VARIANT and FLATTEN
- dbt ephemeral models for transformations
- dbt incremental models using MERGE strategy
- Data quality checks using dbt tests

---

## ğŸ“‚ Project Structure
snowflake-dbt-s3-project/
â”œâ”€â”€ snowflake/
â”‚ â”œâ”€â”€ warehouse_setup.sql
â”‚ â””â”€â”€ storage_integration.sql
â”œâ”€â”€ dbt_project/
â”‚ â””â”€â”€ models/
â”‚ â”œâ”€â”€ staging/
â”‚ â”‚ â””â”€â”€ query1.sql
â”‚ â”œâ”€â”€ marts/
â”‚ â”‚ â””â”€â”€ query2.sql
â”‚ â”œâ”€â”€ schema.yml
â”‚ â””â”€â”€ sources.yml
â””â”€â”€ README.md


---

## ğŸš€ How to Run
```bash
dbt debug
dbt run
dbt test

Use Case:-

This pipeline is suitable for:

Order ingestion systems

Event-based JSON data processing

Cost-optimized incremental analytics pipelines

Future Enhancements:-

Add dbt snapshots (SCD Type 2)

Add documentation generation (dbt docs)

Add advanced tests and freshness checks
